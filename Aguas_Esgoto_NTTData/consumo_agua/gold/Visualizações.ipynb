{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4b38910-218d-488d-b00b-f34b170c6005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 1) Ler a tabela gold\n",
    "# ===========================================\n",
    "df = spark.table(\"classes.gold.fato_consumo_agua\")\n",
    "\n",
    "# ===========================================\n",
    "# 2) Criar o TOP 10 das regiões com maior valor_total\n",
    "# ===========================================\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_top10 = (\n",
    "    df.groupBy(\"regiao\")\n",
    "      .agg(F.max(\"valor_total\").alias(\"maior_valor\"))\n",
    "      .orderBy(F.desc(\"maior_valor\"))\n",
    "      .limit(10)\n",
    ")\n",
    "\n",
    "display(df_top10)\n",
    "\n",
    "# ===========================================\n",
    "# 3) GRÁFICO DE COLUNA (BARRAS VERTICAIS)\n",
    "# ===========================================\n",
    "p = df_top10.plot(\n",
    "    x=\"regiao\",\n",
    "    y=\"maior_valor\",\n",
    "    kind=\"bar\",\n",
    "    title=\"TOP 10 • Regiões com Maior valor_total\",\n",
    ")\n",
    "\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb1f4ce2-137c-41b3-963a-74350495f887",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765222219927}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Scatter plot: Maior valor por ano\n",
    "# ==============================\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# 1) Ler a tabela GOLD\n",
    "df = spark.table(\"classes.gold.fato_consumo_agua\")\n",
    "\n",
    "# 2) Garantir colunas necessárias existem\n",
    "# (Se sua tabela já tem 'ano' como inteiro e 'valor_total' numeric, os casts abaixo são seguros)\n",
    "df = df.withColumn(\"ano\", F.col(\"ano\").cast(\"int\")) \\\n",
    "       .withColumn(\"valor_total\", F.col(\"valor_total\").cast(\"double\"))\n",
    "\n",
    "# 3) Janela para pegar o maior valor por ano\n",
    "w = Window.partitionBy(\"ano\").orderBy(F.desc(\"valor_total\"))\n",
    "\n",
    "df_maior_ano = (\n",
    "    df.withColumn(\"rk\", F.row_number().over(w))\n",
    "      .filter(F.col(\"rk\") == 1)   # pega apenas o TOP 1 de cada ano\n",
    "      .select(\"ano\", \"regiao\", \"valor_total\")\n",
    "      .orderBy(\"ano\")\n",
    ")\n",
    "\n",
    "display(df_maior_ano)   # opcional: ver os dados antes do gráfico\n",
    "\n",
    "# 4) Plot de bolinhas (scatter)\n",
    "# x = ano (numérico), y = valor_total (numérico)\n",
    "p = df_maior_ano.plot(\n",
    "    kind=\"scatter\",\n",
    "    x=\"ano\",\n",
    "    y=\"valor_total\",\n",
    "    title=\"Scatter • Maior Valor Total por Ano\",\n",
    ")\n",
    "\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eea37914-1ccc-4787-9617-9138aa482b35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ==============================\n",
    "# 1. Ler a tabela GOLD já formatada\n",
    "# ==============================\n",
    "df = spark.table(\"classes.gold.top10_regioes_maior_consumo_m3_FORMATADO\")\n",
    "\n",
    "# IMPORTANTE:\n",
    "# A coluna formatada virou string (por causa das vírgulas)\n",
    "# Vamos criar uma coluna numérica limpa para o gráfico.\n",
    "df_num = df.withColumn(\n",
    "    \"maior_consumo_m3_num\",\n",
    "    F.regexp_replace(\"maior_consumo_m3\", \"\\\\.\", \"\")  # remove milhares\n",
    ").withColumn(\n",
    "    \"maior_consumo_m3_num\",\n",
    "    F.regexp_replace(\"maior_consumo_m3_num\", \",\", \".\").cast(\"double\")\n",
    ")\n",
    "\n",
    "display(df_num)\n",
    "\n",
    "# ==============================\n",
    "# 2. Gráfico de barras horizontais (barh)\n",
    "# ==============================\n",
    "p = df_num.plot(\n",
    "    kind=\"barh\",\n",
    "    x=\"regiao\",\n",
    "    y=\"maior_consumo_m3_num\",\n",
    "    title=\"Top 10 Regiões – Maior Consumo por m³ (Barra Horizontal)\"\n",
    ")\n",
    "\n",
    "display(p)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Visualizações",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
